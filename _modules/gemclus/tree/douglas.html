

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>gemclus.tree.douglas &mdash; gemclus 1.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/gemclus.css?v=d1d1afb3" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="../../../_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="../../../_static/documentation_options.js?v=fc837d61"></script>
      <script src="../../../_static/doctools.js?v=9bcbadda"></script>
      <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="../../../_static/js/copybutton.js?v=26522df0"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            gemclus
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quick_start.html">Quick start on GemClus</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../user_guide.html">User Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../api.html">GemClus API</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../history.html">RELEASES</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial - Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../auto_examples/index.html">Example gallery</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">gemclus</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">gemclus.tree.douglas</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for gemclus.tree.douglas</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span><span class="w"> </span><span class="nn">functools</span><span class="w"> </span><span class="kn">import</span> <span class="n">reduce</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">numbers</span><span class="w"> </span><span class="kn">import</span> <span class="n">Integral</span><span class="p">,</span> <span class="n">Real</span>

<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>

<span class="kn">from</span><span class="w"> </span><span class="nn">.._base_gemini</span><span class="w"> </span><span class="kn">import</span> <span class="n">DiscriminativeModel</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_array</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils._param_validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">Interval</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils.extmath</span><span class="w"> </span><span class="kn">import</span> <span class="n">softmax</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">sklearn.utils.validation</span><span class="w"> </span><span class="kn">import</span> <span class="n">check_is_fitted</span>


<div class="viewcode-block" id="Douglas">
<a class="viewcode-back" href="../../../generated/gemclus.tree.Douglas.html#gemclus.tree.Douglas">[docs]</a>
<span class="k">class</span><span class="w"> </span><span class="nc">Douglas</span><span class="p">(</span><span class="n">DiscriminativeModel</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implementation of the `DNDTs optimised using GEMINI leveraging apprised splits` tree algorithm. This model learns</span>
<span class="sd">    clusters by optimising learnable parameters to perform feature-wise soft-binnings and recombine those bins</span>
<span class="sd">    into a single cluster predictions. The parameters are optimised to maximise a generalised mutual information score.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>

<span class="sd">    n_clusters : int, default=3</span>
<span class="sd">        The number of clusters to form as well as the number of output neurons in the neural network.</span>

<span class="sd">    gemini: str, GEMINI instance or None, default=&quot;wasserstein_ova&quot;</span>
<span class="sd">        GEMINI objective used to train this discriminative model. Can be &quot;mmd_ova&quot;, &quot;mmd_ovo&quot;, &quot;wasserstein_ova&quot;,</span>
<span class="sd">        &quot;wasserstein_ovo&quot;, &quot;mi&quot; or other GEMINI available in `gemclus.gemini.AVAILABLE_GEMINI`. Default GEMINIs</span>
<span class="sd">        involve the Euclidean metric or linear kernel. To incorporate custom metrics, a GEMINI can also</span>
<span class="sd">        be passed as an instance. If None, the GEMINI will be the MMD OvA.</span>

<span class="sd">    n_cuts: int, default=1</span>
<span class="sd">        The number of cuts to consider per feature in the soft binning function of the DNDT</span>

<span class="sd">    feature_mask: array of boolean [shape d], default None</span>
<span class="sd">        A boolean vector indicating whether a feature should be considered or not among splits. If None,</span>
<span class="sd">        all features are considered during training.</span>

<span class="sd">    temperature: float, default=0.1</span>
<span class="sd">        The temperature controls the relative importance of logits per leaf soft-binning. A high temperature smoothens</span>
<span class="sd">        the differences in probability whereas a low temperature produces distributions closer to delta Dirac</span>
<span class="sd">        distributions.</span>

<span class="sd">    max_iter: int, default=100</span>
<span class="sd">        The number of epochs for training the model parameters.</span>

<span class="sd">    batch_size: int, default=None</span>
<span class="sd">        The number of samples per batch during an epoch. If set to `None`, all samples will be considered in a single</span>
<span class="sd">        batch.</span>

<span class="sd">    solver: {&#39;sgd&#39;,&#39;adam&#39;}, default=&#39;adam&#39;</span>
<span class="sd">        The solver for weight optimisation.</span>

<span class="sd">        - &#39;sgd&#39; refers to stochastic gradient descent.</span>
<span class="sd">        - &#39;adam&#39; refers to a stochastic gradient-based optimiser proposed by Kingma, Diederik and Jimmy Ba.</span>

<span class="sd">    learning_rate: float, default=1e-2</span>
<span class="sd">        The learning rate hyperparameter for the optimiser&#39;s update rule.</span>

<span class="sd">    verbose: bool, default=False</span>
<span class="sd">        Whether to print progress messages to stdout</span>

<span class="sd">    random_state: int, RandomState instance, default=None</span>
<span class="sd">        Determines random number generation for feature exploration.</span>
<span class="sd">        Pass an int for reproducible results across multiple function calls.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    optimiser_: `AdamOptimizer` or `SGDOptimizer`</span>
<span class="sd">        The optimisation algorithm used for training depending on the chosen solver parameter.</span>
<span class="sd">    labels_: ndarray of shape (n_samples)</span>
<span class="sd">        The labels that were assigned to the samples passed to the :meth:`fit` method.</span>
<span class="sd">    n_iter_: int</span>
<span class="sd">        The number of iterations that the model took for converging.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">_parameter_constraints</span><span class="p">:</span> <span class="nb">dict</span> <span class="o">=</span> <span class="p">{</span>
        <span class="o">**</span><span class="n">DiscriminativeModel</span><span class="o">.</span><span class="n">_parameter_constraints</span><span class="p">,</span>
        <span class="s2">&quot;n_cuts&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Integral</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;left&quot;</span><span class="p">),</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;feature_mask&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">Interval</span><span class="p">(</span><span class="n">Real</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">,</span> <span class="n">closed</span><span class="o">=</span><span class="s2">&quot;neither&quot;</span><span class="p">)],</span>
    <span class="p">}</span>

<div class="viewcode-block" id="Douglas.__init__">
<a class="viewcode-back" href="../../../generated/gemclus.tree.Douglas.html#gemclus.tree.Douglas.__init__">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">n_clusters</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">gemini</span><span class="o">=</span><span class="s2">&quot;wasserstein_ova&quot;</span><span class="p">,</span> <span class="n">n_cuts</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">feature_mask</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">temperature</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
                 <span class="n">max_iter</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">solver</span><span class="o">=</span><span class="s2">&quot;adam&quot;</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-2</span><span class="p">,</span> <span class="n">verbose</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">n_clusters</span><span class="o">=</span><span class="n">n_clusters</span><span class="p">,</span>
            <span class="n">gemini</span><span class="o">=</span><span class="n">gemini</span><span class="p">,</span>
            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
            <span class="n">learning_rate</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">,</span>
            <span class="n">solver</span><span class="o">=</span><span class="n">solver</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n_cuts</span> <span class="o">=</span> <span class="n">n_cuts</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">feature_mask</span> <span class="o">=</span> <span class="n">feature_mask</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span> <span class="o">=</span> <span class="n">temperature</span></div>


    <span class="k">def</span><span class="w"> </span><span class="nf">_leaf_binning</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">cut_points</span><span class="p">):</span>
        <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">cut_points</span><span class="p">)</span>
        <span class="n">W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">n</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
        <span class="n">order</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="n">cut_points</span><span class="p">)</span>
        <span class="n">sorted_cut_points</span> <span class="o">=</span> <span class="n">cut_points</span><span class="p">[</span><span class="n">order</span><span class="p">]</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">1</span><span class="p">),</span> <span class="o">-</span><span class="n">sorted_cut_points</span><span class="p">]))</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">))</span>

        <span class="n">logits</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">W</span> <span class="o">+</span> <span class="n">b</span>

        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">logits</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span><span class="p">),</span> <span class="n">order</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_merge_leaf</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">leaf_res1</span><span class="p">,</span> <span class="n">leaf_res2</span><span class="p">):</span>
        <span class="c1"># Compute feature-wise kronecker product</span>
        <span class="n">product</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="s2">&quot;ij,ik-&gt;ijk&quot;</span><span class="p">,</span> <span class="n">leaf_res1</span><span class="p">,</span> <span class="n">leaf_res2</span><span class="p">)</span>

        <span class="c1"># reshape to 2d</span>
        <span class="k">return</span> <span class="n">product</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">product</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">:])))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_infer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">retain</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="n">leaf_binning</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">z</span><span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf_binning</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span><span class="n">z</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span><span class="p">],</span> <span class="n">z</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="n">cut_iterator</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">leaf_binning</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">)</span>

        <span class="n">all_binnings_results</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">cut_iterator</span><span class="p">)</span>
        <span class="n">all_binnings</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">all_binnings_results</span><span class="p">]</span>
        <span class="n">all_orders</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">all_binnings_results</span><span class="p">]</span>

        <span class="n">leaf</span> <span class="o">=</span> <span class="n">reduce</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_merge_leaf</span><span class="p">,</span> <span class="n">all_binnings</span><span class="p">)</span>

        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">leaf</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_scores_</span>

        <span class="k">if</span> <span class="n">retain</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span> <span class="o">=</span> <span class="n">leaf</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_all_orders</span> <span class="o">=</span> <span class="n">all_orders</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">_all_binnings</span> <span class="o">=</span> <span class="n">all_binnings</span>

        <span class="k">return</span> <span class="n">softmax</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_init_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">random_state</span><span class="p">,</span> <span class="n">X</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
        <span class="c1"># Create the parameters</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_mask</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cuts</span><span class="p">,)))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])]</span>
            <span class="n">num_leaf</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cuts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">feature_mask</span><span class="p">)</span> <span class="o">!=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The boolean feature mask must have as much entries as the number of features&quot;</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span> <span class="o">=</span> <span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">random_state</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cuts</span><span class="p">,</span> <span class="p">))</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
                                     <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">feature_mask</span><span class="p">[</span><span class="n">i</span><span class="p">]]</span>
            <span class="n">num_leaf</span> <span class="o">=</span> <span class="nb">int</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n_cuts</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">**</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">))</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Total will be </span><span class="si">{</span><span class="n">num_leaf</span><span class="si">}</span><span class="s2"> values per sample&quot;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">leaf_scores_</span> <span class="o">=</span> <span class="n">random_state</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">num_leaf</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n_clusters</span><span class="p">))</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_compute_grads</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y_pred</span><span class="p">,</span> <span class="n">gradient</span><span class="p">):</span>
        <span class="c1"># Start by the backprop through the softmax</span>
        <span class="n">y_pred_grad</span> <span class="o">=</span> <span class="n">y_pred</span> <span class="o">*</span> <span class="p">(</span><span class="n">gradient</span> <span class="o">-</span> <span class="p">(</span><span class="n">y_pred</span> <span class="o">*</span> <span class="n">gradient</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>

        <span class="c1"># Then backprop through the final matrix multiplication</span>
        <span class="n">binning_backprop</span> <span class="o">=</span> <span class="n">y_pred_grad</span> <span class="o">@</span> <span class="bp">self</span><span class="o">.</span><span class="n">leaf_scores_</span><span class="o">.</span><span class="n">T</span>
        <span class="n">leaf_score_backprop</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y_pred_grad</span>

        <span class="c1"># Store the update corresponding to the leaf score, negate for maximisation instead of minimisation</span>
        <span class="n">updates</span> <span class="o">=</span> <span class="p">[</span><span class="o">-</span><span class="n">leaf_score_backprop</span><span class="p">]</span>

        <span class="c1"># Then, compute all feature kronecker derivatives</span>
        <span class="n">axes_for_reshape</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span> <span class="o">+</span> <span class="mi">1</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">])</span>
        <span class="n">binning_backprop</span> <span class="o">=</span> <span class="n">binning_backprop</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">axes_for_reshape</span><span class="p">)</span>
        <span class="c1"># We must multiply the binning gradient by all binnings</span>
        <span class="n">binning_backprop</span> <span class="o">*=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_leaf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">axes_for_reshape</span><span class="p">)</span>

        <span class="c1"># Compute individual cut points backprop</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">_</span><span class="p">,</span> <span class="n">cut_points</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">):</span>
            <span class="n">axes_for_sum</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">([</span><span class="mi">1</span> <span class="o">+</span> <span class="n">j</span> <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">j</span><span class="p">])</span>
            <span class="n">softmax_grad</span> <span class="o">=</span> <span class="n">binning_backprop</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">axes_for_sum</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_binnings</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

            <span class="n">bin_grad</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_all_binnings</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span>
                    <span class="n">softmax_grad</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_binnings</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">softmax_grad</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">))</span>  <span class="c1"># Shape Nx(d+1)</span>
            <span class="n">bin_grad</span> <span class="o">/=</span> <span class="bp">self</span><span class="o">.</span><span class="n">temperature</span>

            <span class="c1"># Gradient is directly on the bias, so we only need to do the cumsum backprop after summing on</span>
            <span class="c1"># all samples</span>

            <span class="c1"># We remove the gradient on the constant [0]</span>
            <span class="n">bias_grad</span> <span class="o">=</span> <span class="n">bin_grad</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">0</span><span class="p">)[</span><span class="mi">1</span><span class="p">:]</span>
            <span class="n">cumsum_grad</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">cumsum</span><span class="p">(</span><span class="n">bias_grad</span><span class="p">[::</span><span class="o">-</span><span class="mi">1</span><span class="p">])[::</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>

            <span class="c1"># Take the order back</span>
            <span class="n">cut_grad</span> <span class="o">=</span> <span class="n">cumsum_grad</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">argsort</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_all_orders</span><span class="p">[</span><span class="n">i</span><span class="p">])]</span>

            <span class="c1"># Apply update rule and negate for maximisation instead of minimisation</span>
            <span class="n">updates</span> <span class="o">+=</span> <span class="p">[</span><span class="o">-</span><span class="n">cut_grad</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">updates</span>

    <span class="k">def</span><span class="w"> </span><span class="nf">_get_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">leaf_scores_</span><span class="p">]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">))</span>

<div class="viewcode-block" id="Douglas.find_active_points">
<a class="viewcode-back" href="../../../generated/gemclus.tree.Douglas.html#gemclus.tree.Douglas.find_active_points">[docs]</a>
    <span class="k">def</span><span class="w"> </span><span class="nf">find_active_points</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Calculates the list of cut points that are considered as active for a Douglas tree and some data X. A cut point</span>
<span class="sd">        is active if its value falls within the bounds of its matching feature.</span>

<span class="sd">        Active points can be used for finding features that actively contributed to the clustering.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X: {array-like, sparse matrix} of shape (n_samples, n_features)</span>
<span class="sd">            Test samples.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        active_points: List</span>
<span class="sd">            A list containing the integer indices of features for which the Douglas model has active cut points</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">check_is_fitted</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">check_array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">&lt;</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;The passed data has fewer features than the number of cut points expected for the &quot;</span>
                             <span class="s2">&quot;Douglas model&quot;</span><span class="p">)</span>
        <span class="n">active_points</span> <span class="o">=</span> <span class="p">[]</span>

        <span class="k">for</span> <span class="p">(</span><span class="n">feature_index</span><span class="p">,</span> <span class="n">cut_points</span><span class="p">)</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">cut_points_list_</span><span class="p">:</span>
            <span class="n">feature</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">feature_index</span><span class="p">]</span>
            <span class="n">min_threshold</span> <span class="o">=</span> <span class="n">cut_points</span><span class="o">.</span><span class="n">min</span><span class="p">()</span>
            <span class="n">max_threshold</span> <span class="o">=</span> <span class="n">cut_points</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>

            <span class="c1"># Check of the cut point lists having at least one threshold falling within bounds of the feature</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">feature</span> <span class="o">&lt;=</span> <span class="n">min_threshold</span><span class="p">)</span> <span class="ow">or</span> <span class="n">np</span><span class="o">.</span><span class="n">all</span><span class="p">(</span><span class="n">feature</span> <span class="o">&gt;=</span> <span class="n">max_threshold</span><span class="p">)):</span>
                <span class="n">active_points</span> <span class="o">+=</span> <span class="p">[</span><span class="n">feature_index</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">active_points</span></div>
</div>

</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Louis Ohl.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>