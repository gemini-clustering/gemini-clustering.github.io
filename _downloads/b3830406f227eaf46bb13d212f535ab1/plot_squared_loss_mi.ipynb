{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Clustering with the squared-loss mutual information\n\nThe squared-loss mutual information (SMI) Is a variant of mutual\ninformation proposed in [1]_\n\nIn this variant, the Pearson divergence is considered as\nreplacement for the KL divergence. The resulting cost function\ncan be used with any clustering architecture.\n\nWe show in this example how to combine this loss,\n:class:`gemclus.gemini.ChiSquareGEMINI` with a kernel logistic\nregression.\n\n.. [1] Sugiyama, M., Yamada, M., Kimura, M., & Hachiya, H. (2011).\n        On information-maximization clustering: Tuning parameter\n        selection and analytic solution. ICML 2011.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "from gemclus.linear import LinearModel\nfrom gemclus.gemini import ChiSquareGEMINI\nfrom sklearn import datasets, metrics\nfrom sklearn.metrics import pairwise\nfrom matplotlib import pyplot as plt\nimport numpy as np\n\n# Create the dataset\nX, y = datasets.make_circles(n_samples=200, factor=0.1, noise=0.05, random_state=0)\n# Center data\nX = (X-X.mean(0))/X.std(0)\n\n# Compute the kernel\nkernel = pairwise.pairwise_kernels(X, metric=\"rbf\")\n\n# Create the linear model\nmodel = LinearModel(n_clusters=2,  gemini=ChiSquareGEMINI(), random_state=0)\n\nmodel.fit(kernel) # Linear regression on kernel = kernel model\n\ny_pred = model.predict(kernel)\nprint(metrics.adjusted_rand_score(y, y_pred))\n\n# we can also use generalisation to visualise the decision boundary\n\nx_vals = np.linspace(-3, 3, num=50)\ny_vals = np.linspace(-3, 3, num=50)\nxx, yy = np.meshgrid(x_vals, y_vals)\ngrid_inputs = np.c_[xx.ravel(), yy.ravel()]\nkernelised_grid_inputs = pairwise.pairwise_kernels(grid_inputs, X, metric=\"rbf\")\nzz = model.predict(kernelised_grid_inputs).reshape((50, 50))\n\n# Plot decision boundary with predictions on top\nplt.contourf(xx, yy, zz, alpha=0.5, cmap=\"Blues\")\nplt.scatter(X[:, 0], X[:, 1], c=y_pred, cmap=\"Reds_r\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}