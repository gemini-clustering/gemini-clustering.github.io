{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Grouped Feature selection with a linear model\n\nIn this example, we ask the :class:`gemclus.sparse.SparseLinearMMD` to perform a path where the regularisation penalty\nis progressively increased until all features but 2 are discarded. Moreover, we will produce some categorical variables\nthat are one-hot-encoded and constrain the model to consider these features altogether using the `groups` option of the\nmodel.\n\nThe dataset consists of 2 binomial variables which parameters depend on the cluster (2 clusters to find) with 8 noisy\nvariables. Thus, the optimal solution should find that only 2 features are relevant and sufficient to get the correct\nclustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt\n\nfrom gemclus.sparse import SparseLinearMMD\n\nnp.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a simple synthetic dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate the informative variables that will be the outcome of multinomial distributions\nX1_class_1 = np.random.multinomial(n=1, pvals=np.array([0.05, 0.45, 0.45, 0.05]), size=(50,))\nX2_class_1 = np.random.multinomial(n=1, pvals=np.array([0.1, 0.1, 0.8]), size=(50,))\nX_class_1 = np.concatenate([X1_class_1, X2_class_1], axis=1)\nX1_class_2 = np.random.multinomial(n=1, pvals=np.array([0.45, 0.05, 0.05, 0.45]), size=(50,))\nX2_class_2 = np.random.multinomial(n=1, pvals=np.array([0.8, 0.1, 0.1]), size=(50,))\nX_class_2 = np.concatenate([X1_class_2, X2_class_2], axis=1)\nX_informative = np.concatenate([X_class_1, X_class_2], axis=0) * 2\n\n# Generate noisy variables\nX_noise = np.random.normal(size=(100, 8))\n\nX = np.concatenate([X_informative, X_noise], axis=1)\n\n# The true cluster assignments\ny = np.repeat(np.arange(2), 50)\n\n# Finally, write out the partition of the dataset\ngroups = [np.arange(4), np.arange(4, 7)]\nfor i in range(8):\n    groups += [np.array([i + 7])]\n\nprint(groups, X.shape)\n\n\n# Visualise clusters\ndef rand_jitter(data):\n    return data + np.random.randn(len(data)) * 0.01\n\n\nplt.scatter(rand_jitter(X1_class_1.argmax(1)), rand_jitter(X2_class_1.argmax(1)), c=\"red\")\nplt.scatter(rand_jitter(X1_class_2.argmax(1)), rand_jitter(X2_class_2.argmax(1)), c=\"blue\")\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nCreate the GEMINI clustering model (just a logistic regression) and call the .path method to iteratively select\nfeatures through gradient descent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = SparseLinearMMD(groups=groups, random_state=0, alpha=1)\n\n# Perform a path search to eliminate all features, we lower the threshold to 80% of the max GEMINI in feature selection\nbest_weights, geminis, penalties, alphas, n_features = clf.path(X, keep_threshold=0.8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path results\n\nTake a look at how our features are distributed\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"Selected features: {np.where(np.linalg.norm(best_weights[0], axis=1, ord=2) != 0)}\")\nprint(f\"The model score is {clf.score(X)}\")\nprint(f\"Top gemini score was {max(geminis)}, which settles an optimum of {0.9 * max(geminis)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}