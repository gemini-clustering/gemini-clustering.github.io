{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Feature selection using the Sparse MMD OvO (Logistic regression)\n\nIn this example, we ask the :class:`gemclus.sparse.SparseLinearMMD` to perform a path where the regularisation penalty\nis progressively increased until all features but 2 are discarded. The model then keeps the best weights with the\nminimum number of features that maintains a GEMINI score close to 90% of the maximum GEMINI value encountered during\nthe path.\n\nThe dataset consists of 3 isotropic Gaussian distributions (so 3 clusters to find) in 5d with 20 noisy variables. Thus,\nthe optimal solution should find that only 5 features are relevant and sufficient to get the correct clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn import metrics\n\nfrom gemclus.data import celeux_one\nfrom gemclus.sparse import SparseLinearMMD"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a simple synthetic dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate samples on that are simple to separate with additional p independent noisy variables\nX, y = celeux_one(n=300, p=20, mu=1.7, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nCreate the GEMINI clustering model (just a logistic regression) and call the .path method to iteratively select\nfeatures through gradient descent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = SparseLinearMMD(random_state=0, alpha=1, ovo=True)\n\n# Perform a path search to eliminate all features\nbest_weights, geminis, penalties, alphas, n_features = clf.path(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Path results\n\nTake a look at how the GEMINI score decreased\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(f\"The model score is {clf.score(X)}\")\nprint(f\"Top gemini score was {max(geminis)}, which settles an optimum of {0.9 * max(geminis)}\")\n\n# Highlight the number of selected features and the GEMINI along decreasing increasing alphas\nplt.title(\"GEMINI score depending on $\\\\alpha$\")\nplt.plot(alphas, geminis)\nplt.xlabel(\"$\\\\alpha$\")\nplt.ylabel(\"GEMINI score\")\nplt.ylim(0, max(geminis) + 0.5)\nplt.show()\n\n# We expect the 5 first features\nprint(f\"Selected features: {np.where(np.linalg.norm(best_weights[0], axis=1, ord=2) != 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Clustering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now, evaluate the cluster predictions\ny_pred = clf.predict(X)\nprint(f\"ARI score is {metrics.adjusted_rand_score(y_pred, y)}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}