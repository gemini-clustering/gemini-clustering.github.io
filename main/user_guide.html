

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="./">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>User guide : contents &mdash; gemclus 1.0.1.dev documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=fa44fd50" />
      <link rel="stylesheet" type="text/css" href="_static/css/gemclus.css?v=d1d1afb3" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery.css?v=d2d258e8" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-binder.css?v=f4aeca0c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-dataframe.css?v=2082cf3c" />
      <link rel="stylesheet" type="text/css" href="_static/sg_gallery-rendered-html.css?v=1277b6f3" />

  
      <script src="_static/documentation_options.js?v=49291813"></script>
      <script src="_static/doctools.js?v=9bcbadda"></script>
      <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
      <script src="_static/js/copybutton.js?v=26522df0"></script>
      <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="_static/js/theme.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="GemClus API" href="api.html" />
    <link rel="prev" title="Quick start on GemClus" href="quick_start.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="index.html" class="icon icon-home">
            gemclus
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="quick_start.html">Quick start on GemClus</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Documentation</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="current reference internal" href="#">User Guide</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#discriminative-clustering">Discriminative clustering</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#definition">Definition</a></li>
<li class="toctree-l3"><a class="reference internal" href="#choosing-a-model">Choosing a model</a></li>
<li class="toctree-l3"><a class="reference internal" href="#the-gemini-approach">The GEMINI approach</a></li>
<li class="toctree-l3"><a class="reference internal" href="#extending-regularising-models">Extending / Regularising models</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#content-of-the-package">Content of the package</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#which-geminis-are-implemented">Which GEMINIs are implemented</a></li>
<li class="toctree-l3"><a class="reference internal" href="#what-discriminative-distributions-are-available">What discriminative distributions are available</a><ul>
<li class="toctree-l4"><a class="reference internal" href="#a-summary-of-what-is-implemented">A summary of what is implemented</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#basic-examples">Basic examples</a></li>
<li class="toctree-l2"><a class="reference internal" href="#references">References</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="api.html">GemClus API</a></li>
<li class="toctree-l1"><a class="reference internal" href="history.html">RELEASES</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Tutorial - Examples</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="auto_examples/index.html">Example gallery</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">gemclus</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">User guide : contents</li>
      <li class="wy-breadcrumbs-aside">
            <a href="_sources/user_guide.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="user-guide">
<span id="id1"></span><h1>User Guide<a class="headerlink" href="#user-guide" title="Link to this heading">¶</a></h1>
<section id="discriminative-clustering">
<h2>Discriminative clustering<a class="headerlink" href="#discriminative-clustering" title="Link to this heading">¶</a></h2>
<section id="definition">
<h3>Definition<a class="headerlink" href="#definition" title="Link to this heading">¶</a></h3>
<p>Clustering is the art of separating data samples <span class="math notranslate nohighlight">\(x\)</span> into <span class="math notranslate nohighlight">\(K\)</span> groups called <em>clusters</em>.</p>
<p>We take the word discriminative in the sense of Minka <a class="footnote-reference brackets" href="#id21" id="id2" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>. In the context of clustering, this means that do not
set any hypotheses on the data distribution and only seek to cluster data by directly designing a clustering
distribution:</p>
<div class="math notranslate nohighlight">
\[p_\theta(y \mid x),\]</div>
<p>where <span class="math notranslate nohighlight">\(y\)</span> is the cluster to identify and <span class="math notranslate nohighlight">\(\theta\)</span> are the parameters of the discriminative distribution.</p>
</section>
<section id="choosing-a-model">
<h3>Choosing a model<a class="headerlink" href="#choosing-a-model" title="Link to this heading">¶</a></h3>
<p>Any function that takes the data as input and returns a vector in a <span class="math notranslate nohighlight">\(K-1\)</span>-simplex can be used as a discriminative
clustering distribution. For example, if we believe that the data is linearly separable, we can use a logistic
regression:</p>
<div class="math notranslate nohighlight">
\[p_\theta (y = k \mid x) \propto \langle w_k, x \rangle + b_k.\]</div>
<p>Then, the parameters to learn are <span class="math notranslate nohighlight">\(\theta = \{w_k, b_k\}_{k=1}^K\)</span>.</p>
<p>If we want more complex boundaries, any neural network that finishes with a softmax activation can be used. In other
words, the choice of the type of decision boundary should guide the choice of clustering distribution.</p>
</section>
<section id="the-gemini-approach">
<h3>The GEMINI approach<a class="headerlink" href="#the-gemini-approach" title="Link to this heading">¶</a></h3>
<p>Learning parameters <span class="math notranslate nohighlight">\(\theta\)</span> in discriminative clustering is challenging because the absence of hypothesis on the
data distribution prevents us from calculating any likelihood.</p>
<p>In 1991, Bridle, Heading and MacKay <a class="footnote-reference brackets" href="#id20" id="id3" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a> proposed to optimise the parameters such that they maximise mutual information:</p>
<div class="math notranslate nohighlight">
\[\mathcal{I} = \mathbb{E}_{y\sim p_\theta(y)} \left[D_\text{KL} (p_\theta(x\mid y) \| p_\text{data}(x))\right].\]</div>
<p>Mutual information has then stayed an essential component of discriminative clustering models. By comparison with
classification contexts, it is an objective function we can use independently of the form taken by the
model <span class="math notranslate nohighlight">\(p_\theta(y\mid x)\)</span>.</p>
<p>The generalised mutual information (GEMINI) is an extension of mutual information that replaces the Kullback-Leibler
divergence <span class="math notranslate nohighlight">\(D_\text{KL}\)</span> by any other statistical distance <span class="math notranslate nohighlight">\(D\)</span>. It comes with two different versions.
The first approach, named <em>one-vs-all</em> (OvA) seeks to discriminate the individual cluster distributions from the data
distribution:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{y \sim p_\theta(y)} \left[ D(p_\theta(x|y) \| p(x))\right].\]</div>
<p>The second approach is the <em>one-vs-one</em> (OvO) version that compares two independently drawn cluster distributions:</p>
<div class="math notranslate nohighlight">
\[\mathbb{E}_{y_1, y_2 \sim p_\theta(y)} \left[ D(p_\theta(x|y_1) \| p_\theta(x | y_2))\right].\]</div>
<p>The specificity of GEMINI is that it involves distances in which the Bayes Theorem can easily be performed to get
a tractable objective that we cane valuate using only clustering probabilities. Hence, models trained with GEMINI
are discriminative models <span class="math notranslate nohighlight">\(p_\theta(y|x)\)</span> without any parametric assumption.</p>
<p>Note that mutual information and the K-Means loss are special cases of GEMINI.</p>
</section>
<section id="extending-regularising-models">
<h3>Extending / Regularising models<a class="headerlink" href="#extending-regularising-models" title="Link to this heading">¶</a></h3>
<p>Owing to the decoupling between the choice of the clustering model and the objective function to learn it, it is
possible to add regularisation that constraint the model <span class="math notranslate nohighlight">\(p_\theta(y\mid x)\)</span>. For example, we propose to
add <span class="math notranslate nohighlight">\(\ell_2\)</span> penalty on logistic regressions in <a class="reference internal" href="generated/gemclus.linear.RIM.html#gemclus.linear.RIM" title="gemclus.linear.RIM"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.linear.RIM</span></code></a>, taken from Krause, Perona and
Gomes <a class="footnote-reference brackets" href="#id22" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a>.</p>
<p>We also propose models that incorporate feature selection using group-lasso penalty, inspired from LassoNet.
Selecting feature can be interesting in the context of clustering for helping interpretation of clusters.</p>
</section>
</section>
<section id="content-of-the-package">
<h2>Content of the package<a class="headerlink" href="#content-of-the-package" title="Link to this heading">¶</a></h2>
<section id="which-geminis-are-implemented">
<h3>Which GEMINIs are implemented<a class="headerlink" href="#which-geminis-are-implemented" title="Link to this heading">¶</a></h3>
<p>All GEMINIs from our initial work are available <a class="footnote-reference brackets" href="#id28" id="id5" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a>: MMD and Wasserstein distances are present for geometrical
considerations, as well as Kullback-Leibler divergence, Total Variation distance and squared Hellinger distance.
Both OvA and OvO implementations are present in all models. The OvO mode can be set in most
clustering model by adding <code class="code docutils literal notranslate"><span class="pre">ovo=True</span></code> in the constructor of a model.</p>
<p>Some models propose readily integrated GEMINIs, but it is also possible to set a custom GEMINI for some models.</p>
<p>The Wasserstein distance requires a distance function in the data space to compute. We directly propose all distances
available from <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise_distances</span></code>, with the Euclidean distance by default.
In the same manner, we provide all kernels available from <code class="xref py py-class docutils literal notranslate"><span class="pre">sklearn.metrics.pairwise_kernels</span></code> for the MMD, with
the linear kernel by default. For both GEMINIs, it is possible as well to involve a precomputed distance or kernel of
your own that must be then passed to the GEMINI.</p>
<p>All loss functions we propose are located in the module <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini</span></code>.</p>
</section>
<section id="what-discriminative-distributions-are-available">
<h3>What discriminative distributions are available<a class="headerlink" href="#what-discriminative-distributions-are-available" title="Link to this heading">¶</a></h3>
<p>We propose several clustering distributions depending on the purpose:</p>
<ul class="simple">
<li><p>Logistic regressions, kernel regressions in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.linear</span></code></p></li>
<li><p>2-layer Multi-Layered-Perceptrons with ReLU activations in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.mlp</span></code></p></li>
<li><p>Decision trees (only compatible with the MMD GEMINI) in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.tree</span></code></p></li>
<li><p>Differentiable trees in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.tree</span></code></p></li>
<li><p>Sparse models in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.sparse</span></code></p></li>
<li><p>Nonparametric models in <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.nonparametric</span></code></p></li>
</ul>
<p>The sparse models are logistic regressions and MLP. Sparse means that we achieve feature selection along clustering.
The sparse architecture of the MLP is inspired from <a class="reference external" href="https://lassonet.ml/">LassoNet</a> <a class="footnote-reference brackets" href="#id27" id="id6" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a> which
adds a linear skip connection between the inputs and clustering output. These sparse versions are located</p>
<p>If you want to use another model, you can derive the <a class="reference internal" href="generated/gemclus.DiscriminativeModel.html#gemclus.DiscriminativeModel" title="gemclus.DiscriminativeModel"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.DiscriminativeModel</span></code></a>
class and rewrite its hidden methods <code class="code docutils literal notranslate"><span class="pre">_infer</span></code>, <code class="code docutils literal notranslate"><span class="pre">_get_weights</span></code>, <code class="code docutils literal notranslate"><span class="pre">_init_params</span></code> and
<code class="code docutils literal notranslate"><span class="pre">_compute_grads</span></code>. An example
of extension is given <a class="reference external" href="auto_examples/_general/plot_custom_model.html">here</a></p>
<section id="a-summary-of-what-is-implemented">
<h4>A summary of what is implemented<a class="headerlink" href="#a-summary-of-what-is-implemented" title="Link to this heading">¶</a></h4>
<p>We hope that GemClus will keep on growing. We seek to implement methods and datasets that can be relevant in
discriminative clustering.</p>
<table class="docutils align-default" id="id31">
<caption><span class="caption-text">Models</span><a class="headerlink" href="#id31" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 60.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Class/Function</p></th>
<th class="head"><p>Source paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="generated/gemclus.linear.RIM.html#gemclus.linear.RIM" title="gemclus.linear.RIM"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.linear.RIM</span></code></a>, <a class="reference internal" href="generated/gemclus.linear.KernelRIM.html#gemclus.linear.KernelRIM" title="gemclus.linear.KernelRIM"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.linear.KernelRIM</span></code></a></p></td>
<td><p>Krause, Perona and Gomes <a class="footnote-reference brackets" href="#id22" id="id7" role="doc-noteref"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/gemclus.sparse.SparseLinearMI.html#gemclus.sparse.SparseLinearMI" title="gemclus.sparse.SparseLinearMI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.sparse.SparseLinearMI</span></code></a></p></td>
<td><p>França, Rizzo and Vogelstein <a class="footnote-reference brackets" href="#id24" id="id8" role="doc-noteref"><span class="fn-bracket">[</span>5<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/gemclus.tree.Kauri.html#gemclus.tree.Kauri" title="gemclus.tree.Kauri"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.tree.Kauri</span></code></a></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id30" id="id9" role="doc-noteref"><span class="fn-bracket">[</span>11<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">sparse.SparseMLPModel</span></code></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id29" id="id10" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a>, Lemhadri et al <a class="footnote-reference brackets" href="#id27" id="id11" role="doc-noteref"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-even"><td><p><code class="xref py py-class docutils literal notranslate"><span class="pre">sparse.SparseLinearModel</span></code></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id29" id="id12" role="doc-noteref"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></a></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id32">
<caption><span class="caption-text">Objective functions</span><a class="headerlink" href="#id32" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 60.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Class/Function</p></th>
<th class="head"><p>Source paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="generated/gemclus.gemini.WassersteinGEMINI.html#gemclus.gemini.WassersteinGEMINI" title="gemclus.gemini.WassersteinGEMINI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.WassersteinGEMINI</span></code></a>, <a class="reference internal" href="generated/gemclus.gemini.TVGEMINI.html#gemclus.gemini.TVGEMINI" title="gemclus.gemini.TVGEMINI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.TVGEMINI</span></code></a>,
<a class="reference internal" href="generated/gemclus.gemini.HellingerGEMINI.html#gemclus.gemini.HellingerGEMINI" title="gemclus.gemini.HellingerGEMINI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.HellingerGEMINI</span></code></a></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id28" id="id13" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/gemclus.gemini.MMDGEMINI.html#gemclus.gemini.MMDGEMINI" title="gemclus.gemini.MMDGEMINI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.MMDGEMINI</span></code></a></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id28" id="id14" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a>, <a class="footnote-reference brackets" href="#id26" id="id15" role="doc-noteref"><span class="fn-bracket">[</span>7<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-even"><td><p><a class="reference internal" href="generated/gemclus.gemini.MI.html#gemclus.gemini.MI" title="gemclus.gemini.MI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.MI</span></code></a></p></td>
<td><p>Bridle, Heading and MacKay <a class="footnote-reference brackets" href="#id20" id="id16" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/gemclus.gemini.ChiSquareGEMINI.html#gemclus.gemini.ChiSquareGEMINI" title="gemclus.gemini.ChiSquareGEMINI"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.gemini.ChiSquareGEMINI</span></code></a></p></td>
<td><p>Sugiyama et al <a class="footnote-reference brackets" href="#id23" id="id17" role="doc-noteref"><span class="fn-bracket">[</span>4<span class="fn-bracket">]</span></a></p></td>
</tr>
</tbody>
</table>
<table class="docutils align-default" id="id33">
<caption><span class="caption-text">Dataset</span><a class="headerlink" href="#id33" title="Link to this table">¶</a></caption>
<colgroup>
<col style="width: 60.0%" />
<col style="width: 40.0%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Class/Function</p></th>
<th class="head"><p>Source paper</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference internal" href="generated/gemclus.data.gstm.html#gemclus.data.gstm" title="gemclus.data.gstm"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.data.gstm</span></code></a></p></td>
<td><p>Ohl et al <a class="footnote-reference brackets" href="#id28" id="id18" role="doc-noteref"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></a></p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference internal" href="generated/gemclus.data.celeux_one.html#gemclus.data.celeux_one" title="gemclus.data.celeux_one"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.data.celeux_one</span></code></a>, <a class="reference internal" href="generated/gemclus.data.celeux_two.html#gemclus.data.celeux_two" title="gemclus.data.celeux_two"><code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.data.celeux_two</span></code></a></p></td>
<td><p>Celeux et al <a class="footnote-reference brackets" href="#id25" id="id19" role="doc-noteref"><span class="fn-bracket">[</span>6<span class="fn-bracket">]</span></a></p></td>
</tr>
</tbody>
</table>
</section>
</section>
</section>
<section id="basic-examples">
<h2>Basic examples<a class="headerlink" href="#basic-examples" title="Link to this heading">¶</a></h2>
<p>We provide some basic examples in the <a class="reference external" href="auto_examples/index.html">Example gallery</a>, including clustering of simple
distribution and how to perform feature selection using sparse models from <code class="xref py py-class docutils literal notranslate"><span class="pre">gemclus.sparse</span></code>.</p>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Link to this heading">¶</a></h2>
<aside class="footnote-list brackets">
<aside class="footnote brackets" id="id20" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id3">1</a>,<a role="doc-backlink" href="#id16">2</a>)</span>
<p>Bridle, J., Heading, A., &amp; MacKay, D. (1991). <a class="reference external" href="https://proceedings.neurips.cc/paper/1991/hash/a8abb4bb284b5b27aa7cb790dc20f80b-Abstract.html">Unsupervised Classifiers, Mutual Information and ‘Phantom
Targets</a>.
Advances in Neural Information Processing Systems, 4.</p>
</aside>
<aside class="footnote brackets" id="id21" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id2">2</a><span class="fn-bracket">]</span></span>
<p>Minka, T. (2005). <a class="reference external" href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/02/tr-2005-144.pdf">Discriminative models, not discriminative training</a>.
Technical Report MSR-TR-2005-144, Microsoft Research.</p>
</aside>
<aside class="footnote brackets" id="id22" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>3<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id4">1</a>,<a role="doc-backlink" href="#id7">2</a>)</span>
<p>Krause, A., Perona, P., &amp; Gomes, R. (2010).
<a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2010/file/42998cf32d552343bc8e460416382dca-Paper.pdf">Discriminative Clustering by Regularized Information Maximization</a>.
In J. Lafferty, C. Williams, J. Shawe-Taylor, R. Zemel, &amp; A. Culotta (Eds.), Advances in Neural Information
Processing Systems (Vol. 23).</p>
</aside>
<aside class="footnote brackets" id="id23" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id17">4</a><span class="fn-bracket">]</span></span>
<p>Sugiyama, M., Yamada, M., Kimura, M., &amp; Hachiya, H. (2011). <a class="reference external" href="http://www.icml-2011.org/papers/61_icmlpaper.pdf">On Information-Maximization Clustering: Tuning
Parameter Selection and Analytic Solution</a>. In Proceedings of
the 28th International Conference on Machine Learning (ICML-11) (pp. 65-72).</p>
</aside>
<aside class="footnote brackets" id="id24" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id8">5</a><span class="fn-bracket">]</span></span>
<p>Kong, Y., Deng, Y., &amp; Dai, Q. (2014). <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/6935074">Discriminative Clustering and Feature Selection for Brain MRI Segmentation</a>. IEEE Signal Processing Letters, 22(5), 573-577.</p>
</aside>
<aside class="footnote brackets" id="id25" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id19">6</a><span class="fn-bracket">]</span></span>
<p>Celeux, G., Martin-Magniette, M. L., Maugis-Rabusseau, C., &amp; Raftery, A. E. (2014). <a class="reference external" href="http://www.numdam.org/item/JSFS_2014__155_2_57_0/">Comparing Model Selection
and Regularization Approaches to Variable Selection in Model-Based Clustering</a>. Journal de la Societe francaise de statistique, 155(2),
57-71.</p>
</aside>
<aside class="footnote brackets" id="id26" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id15">7</a><span class="fn-bracket">]</span></span>
<p>França, G., Rizzo, M. L., &amp; Vogelstein, J. T. (2020). <a class="reference external" href="https://ieeexplore.ieee.org/abstract/document/9103121">Kernel k-Groups via Hartigan’s Method</a>. IEEE transactions on pattern analysis and machine
intelligence, 43(12), 4411-4425.</p>
</aside>
<aside class="footnote brackets" id="id27" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>8<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id6">1</a>,<a role="doc-backlink" href="#id11">2</a>)</span>
<p>Lemhadri, I., Ruan, F., Abraham, L., &amp; Tibshirani, R. (2021). <a class="reference external" href="https://lassonet.ml/">LassoNet: A Neural Network with Feature Sparsity</a>. Journal of Machine Learning Research, 22(127), 1–29.</p>
</aside>
<aside class="footnote brackets" id="id28" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>9<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id5">1</a>,<a role="doc-backlink" href="#id13">2</a>,<a role="doc-backlink" href="#id14">3</a>,<a role="doc-backlink" href="#id18">4</a>)</span>
<p>Ohl, L., Mattei, P. A., Bouveyron, C., Harchaoui, W., Leclercq, M., Droit, A., &amp; Precioso, F. (2022).
<a class="reference external" href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/16294049ed8de15830ac0b569b97f74a-Abstract-Conference.html">Generalised Mutual Information for Discriminative Clustering</a>.
Advances in Neural Information Processing Systems, 35, 3377-3390.</p>
</aside>
<aside class="footnote brackets" id="id29" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span>10<span class="fn-bracket">]</span></span>
<span class="backrefs">(<a role="doc-backlink" href="#id10">1</a>,<a role="doc-backlink" href="#id12">2</a>)</span>
<p>Ohl, L., Mattei, P. A., Bouveyron, C., Leclercq, M., Droit, A., &amp; Precioso, F. (2024).
<a class="reference external" href="https://link.springer.com/article/10.1007/s11222-024-10467-9">Sparse and Geometry-Aware Generalisation of the Mutual Information for Joint Discriminative Clustering and Feature
Selection</a>. Statistics and Computing, 34(5), 155.</p>
</aside>
<aside class="footnote brackets" id="id30" role="doc-footnote">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id9">11</a><span class="fn-bracket">]</span></span>
<p>Ohl, L., Mattei, P. A., Leclercq, M., Droit, A., &amp; Precioso, F. (2024). <a class="reference external" href="https://arxiv.org/abs/2402.12232">Kernel KMeans Clustering Splits for
End-to-End Unsupervised Decision Trees</a>. arXiv preprint arXiv:2402.12232.</p>
</aside>
</aside>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="quick_start.html" class="btn btn-neutral float-left" title="Quick start on GemClus" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="api.html" class="btn btn-neutral float-right" title="GemClus API" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2023, Louis Ohl.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>