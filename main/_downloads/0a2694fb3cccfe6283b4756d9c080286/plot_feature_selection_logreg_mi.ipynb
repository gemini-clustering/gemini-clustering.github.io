{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Feature selection using the Sparse Linear MI (Logistic regression)\n\nIn this example, we ask the :class:`gemclus.sparse.SparseLinearMI` to perform a path where the regularisation penalty\nis progressively increased until all features but 2 are discarded. The model then keeps the best weights with the\nminimum number of features that maintains a GEMINI score close to 50% of the maximum GEMINI value encountered during\nthe path.\n\nContrary to the MMD sparse model, this one is not guided by specific kernel in the data space. That is why the\nacceptance threshold for best score is lowered to 50% instead of 90% like other models. A very similar model can be\nfound in `Discriminative Clustering and Feature Selection for Brain MRI Segmentation` proposed by Kong et al. (2014).\n\nThe dataset consists of 3 isotropic Gaussian distributions (so 3 clusters to find) in 5d with 20 noisy variables. Thus,\nthe optimal solution should find that only 5 features are relevant and sufficient to get the correct clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\nfrom matplotlib import pyplot as plt\nfrom sklearn import metrics, decomposition\n\nfrom gemclus.data import celeux_one\nfrom gemclus.sparse import SparseLinearMI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load a simple synthetic dataset\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Generate samples on that are simple to separate with additional p independent noisy variables\nX, y = celeux_one(n=300, p=20, mu=1.7, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Train the model\nCreate the GEMINI clustering model (just a logistic regression) and call the .path method to iteratively select\nfeatures through gradient descent.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "clf = SparseLinearMI(random_state=0, alpha=1)\n\n# Perform a path search to eliminate all features\nbest_weights, geminis, penalties, alphas, n_features = clf.path(X, keep_threshold=0.5)\n\n# We expect the 5 first features\nprint(f\"Selected features: {np.where(np.linalg.norm(best_weights[0], axis=1, ord=2) != 0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Clustering\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# Now, evaluate the cluster predictions\ny_pred = clf.predict(X)\nprint(f\"ARI score is {metrics.adjusted_rand_score(y_pred, y)}\")\n\n# Let's make a small PCA for visualisation purpose and distinguish true labels from clustering labels\nX_pca = decomposition.PCA(n_components=2).fit_transform(X)\n\nfor k in range(3):\n    class_indices, = np.where(y==k)\n    plt.scatter(X_pca[class_indices,0], X_pca[class_indices,1], c=y_pred[class_indices], marker=[\"+\",\"x\",\"o\"][k])\nplt.axis(\"off\")\nplt.title(\"PCA of celeux 1 dataset clustered with a MI-trained LASSO\")\nplt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}